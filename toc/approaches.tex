\subsection{Known Approaches to Range Queries}\label{subsec:approaches}

In this subsection, we give a~brief overview of a~rich variety of known
algorithms for the range queries problem. We say that an algorithm has type
$(f(n), g(n))$ if it spends $f(n)$ time on preprocessing the input sequence,
and then answers any query in time $g(n)$.

\textbf{No preprocessing.} A~naive algorithm skips the preprocessing stage and
answers a~query $(l,r)$ directly in time $O(r-l+1)$. It therefore has type
$(O(1), O(n))$.

\textbf{Full preprocessing.} One may precompute the answers to all possible
queries to be able to answer any subsequent query immediately. Using dynamic
programming, it is possible to precompute the answers to all $\Theta(n^2)$
queries in time $O(n^2)$: for this, it is enough to process the queries in
order of increasing length. This gives an $(O(n^2), O(1))$ algorithm.

\textbf{Fixed length queries (sliding window).} In case one is promised that all
the queries are going to have the same length~$m$, it is possible to do
an~$O(n)$ time preprocessing and then to answer any query in time $O(1)$. For
this, one partitions the input sequence of size~$n$ into $\frac nm$ blocks of
size~$m$. For each block, one computes all its prefixes and suffixes in time
$O(m)$. The overall running time is $O(\frac nm \cdot m)=O(n)$. Then, each query
of length~$m$ touches at most two consecutive blocks and can be answered by
taking a~precomputed suffix of the left block and a~precomputed prefix of the
right block in time $O(1)$. This, in particular, implies that, given a~sequence
of length~$n$ and an integer $1 \le m \le n$, one may slide a~window of
length~$m$ through the sequence and to output the answer to all such window
queries in time $O(n)$.


\textbf{Prefix sums.} In case the semigroup operation has an \emph{easily
computable inverse}, there is an~$(O(n), O(1))$ algorithm. We
illustrate this for a~group $(\mathbb{Z}, +)$. Given $x_1, \dotsc, x_n$, we
compute $(n+1)$ prefix sums:
\(S_0=0,\, S_1=x_1,\, S_2=x_1+x_2, \dotsc, S_n=x_1+\dotsb+x_n\,.\)
This can be done in time $O(n)$ since $S_i=S_{i-1}+x_i$. Then, the answer to any
query $(l,r)$ is just $S_r-S_{l-1}$.

Note that the algorithm above solves a \emph{static} version of the problem. For
the \emph{dynamic} version, where one is allowed to change the elements of the
input sequence, there is a~data structure known as Fenwick's
tree~\cite{DBLP:journals/spe/Fenwick94}. It allows to change any element as well
as to retrieve any prefix sum in time $O(\log n)$.

\textbf{Block decomposition.} One decomposes the input range $(1,n)$ into
$n/b$~blocks of length~$b$ and then computes, for each block, all its prefixes
and suffixes. This can be done in time $O(n)$. Then, for each query, if it lies
entirely in a~block, we compute the answer directly (hence, in time at most
$O(b)$). If it crosses a~number of blocks, we decompose it into a~suffix of
a~block, a~number of consecutive blocks, and a~prefix of a~block. This allows us
to answer such long queries in time $O(n/b)$. Setting $b=\sqrt{n}$ to balance
both cases, we get a~$(O(n), O(\sqrt{n}))$-algorithm.

\textbf{Sparse table.} This data structure works for idempotent semigroups
(\emph{bands}) and has the type $(O(n\log n), O(1))$. We illustrate its main idea
for the \emph{range minimum query} (RMQ)  (i.e., for a~semigroup
$(\mathbb{Z}, \min)$). One precomputes answers to $O(n\log n)$ queries---namely,
those whose length is a~power of~2. More formally, for all $0 \le k \le \log_2n$
and $1 \le i \le n-2^k+1$, let $S_{k,i}$ be the answer to a~query $(i, i+2^k-1)$:
\(S_{k,i}=x_i \circ x_{i+1} \circ \dotsb \circ x_{i+2^k-1} \, .\)
Since any range of length $2^k$ consists of two ranges of length $2^{k-1}$, one
can compute all $S_{k,i}$'s in time $O(n\log n)$ using dynamic programming.
Then, any range $(l,r)$ can be covered by two precomputed ranges: if $k$~is the
smallest integer such that $2^k \ge (r-l+1)/2$, then the answer to this query
is $S_{k,l} \circ S_{k,r-2^k+1}$ (idempotency is required since we are covering
the range, but not partitioning it). This gives an $(O(n\log n), O(1))$
algorithm.

\textbf{Hybrid strategy.} One may extend the block decomposition
approach further and use one efficient data structure on top of
blocks and possibly a~different data structure for each block.
Namely, we decompose the input range into blocks of size~$b$,
use a~$(p_1(n), q_1(n))$-algorithm on top of blocks and
a~$(p_2(n), q_2(n))$-algorithm within each block. The resulting algorithm then
has type
\[(O(n + p_1(n / b) + (n / b) \cdot p_2(b), O(q_1(n/b) + q_2(b))) \, .\]
For example, for the range minimum problem, combining the sparse table data
structure ($p_1(n)=O(n\log n)$, $q_1(n)=O(1)$) with no preprocessing technique
($p_2(n)=O(1)$, $q_2=O(n)$) and block size $b=\log n$, gives
an~$(O(n), O(\log n))$-algorithm. Another example: using sparse table in both
cases (with block size $b=\log n$) gives an $(O(n\log\log n), O(1))$ algorithm.

% reference: https://web.stanford.edu/class/cs166/lectures/00/Slides00.pdf

\textbf{Segment tree.} The segment tree data structure is also based on dynamic
programming ideas and works for any semigroup. Consider the following complete
binary tree with $O(n)$ nodes: the root is labelled by a~query $(1,n)$, the two
children of each inner node $(l,r)$ are labelled by the left and right halves of
the current query (i.e., $(l,m)$ and $(m+1,r)$ where $m=(l+r)/2$), the leaves
are labelled by length one queries. Going from leaves to the root, one can
precompute the answers to all the queries in this tree in time $O(n)$. Then, it
is possible to show that any query $(l,r)$ can be  partitioned into $O(\log n)$
queries that are stored in the tree. This gives an $(O(n), O(\log n))$
algorithm. It should be noted that the segment tree can also be used to solve
the dynamic version of the range queries problem efficiently: to change the
value of one of the elements of the input sequence, one needs to adjust the
answers to $O(\log n)$ queries stored in the tree.

\textbf{Algorithms by Yao and by Alon and Schieber.}
Yao~\cite{DBLP:conf/stoc/Yao82} showed that, for any semigroup, it is possible
to preprocess the input sequence in time $O(n)$ so that to further answer any
query in time $O(\alpha(n))$ where $\alpha(n)$ is the inverse Ackermann function
and proved a~matching lower bound. Later, Alon and
Schieber~\cite{Alon87optimalpreprocessing} studied a~more specific question:
what is the minimum number of semigroup operations needed at the preprocessing
stage for being able to then answer any query in at most $k$~steps? They proved
matching lower and upper bounds for every~$k$. As a~special case, they show how
to preprocess the input sequence in time $O(n\log n)$ so that to answer any
subsequent query by applying at most one semigroup operation. This algorithm
generalizes the sparse table data structure (as it does not require the
semigroup to be idempotent) and is particularly easy to describe. It is based on
the divide-and-conquer paradigm. Let $m=n/2$. We precompute answers to all
queries of the form $(i,m)$ and $(m+1,j)$, where $1 \le i \le m$ and
$m+1 \le j \le n$ (i.e., suffixes of the left half and prefixes of the right
half). This allows to answer in a~single step any query that intersects the
middle of the sequence, i.e., queries $(l,r)$ such that $l \le m \le r$. All the
remaining preprocessing boils down to answering queries that lie entirely in
either left or right half. This can be done recursively for the halves. The
corresponding recurrence relation $T(n)=2T(n/2)+O(n)$ implies an upper bound
$O(n\log n)$ on preprocessing time (and hence, the number of semigroup
operations).

\textbf{$(O(n), O(1))$-type algorithms.}
There is a~sequence of $(O(n), O(1))$-type algorithms designed specifically to
the range minimum query problem and a~related problem called least common
ancestor (LCA) \cite{DBLP:journals/siamcomp/BerkmanV93,
DBLP:journals/jal/BenderFPSS05,
DBLP:conf/latin/BenderF00,
DBLP:conf/cpm/FischerH06}. Here, we briefly sketch the algorithm by Bender and
Farach-Colton. Its main idea is to first reduce RMQ to LCA (the least common
ancestor problem). One then reduces LCA back to RMQ and notices that the
resulting instance of RMQ has a~convenient property: the difference between any
two consecutive elements is $\pm 1$. This property allows to do the following
trick: we precompute answers to all relatively short queries (this can be done
even without knowing the input sequence because of the $\pm 1$ property); we
also partition the input sequence into blocks and build a~segment tree out of
these blocks.
